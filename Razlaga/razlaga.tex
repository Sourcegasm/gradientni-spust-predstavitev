\documentclass[a4paper, 12pt]{article}
\usepackage[slovene]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{tikz}
\usepackage{pgfplots}

\setlength{\parindent}{0px}
\setlength{\parskip}{10px}

\begin{document}

	\section*{Linearna regresija}
	\input{linearna_regresija}

	\section*{Gradientni spust}
	\input{gradientni_spust/gradientni_spust}
	
	\section*{Prilagajanje premice}
	\input{prilagajanje_premice}

	

	\subsection*{Delni odvodi}
	\paragraph{}
	Funkcija je odvisna od večih spremenljivk, zato jo moramo odvajati za vsako spremenljivko posebej. Ker nam odvod ene spremenljivke pove kako se funkcija obnaša samo po tej spremenljivki, temu rečemu delni odvod.


	$$\frac{\partial \varepsilon}{\partial a} =
	\sum_{i=1}^{N} 2 \frac{\partial (a x_i - b - y_i)}{\partial a} =
	2 \sum_{i=1}^{N} (a x_i - b - y_i)x_i$$

	$$\frac{\partial \varepsilon}{\partial b} =
	\sum_{i=1}^{N} 2 \frac{\partial (a x_i - b - y_i)}{\partial b} =
	2 \sum_{i=1}^{N} (a x_i - b - y_i)(-1) = -2 \sum_{i=1}^{N} (a x_i - b - y_i)$$

	Rešitev najdemo tako, da ugotovimo, pri katerih $a$ in $b$ sta odvoda enaka 0. To lahko rešimo z uporabmo matrik, vendar tega ne zamo, zato se bomo tega lotili s primitvno metodo gradientnega spusta.


	\section*{Linerana regresija elipse}
	\paragraph{}
	Imamo $N$ točk krožnice nekega planeta $T_1(x_1, y_1), T_2(x_2, y_2) \ldots, T_n(x_n, y_n)$. Podobno kot pri prej"snjem primeru, bomo tudi tokrat iskali funkcijo, ki se to"ckam najbolj prilega. Tokrat bomo namesto premice iskali elipso, saj se elipsa seveda bolj prilega kro"znici planeta kot pa premica.


	Elipsa je sto"znica, zato zapišemo splošno enačbo za sto"znice:
	$$Ax^2 + Bxy + Cy^2 + Dx + Ey + F = 0$$

	\paragraph{}
	Tako kot prej se nam bo pojavila napaka, ki jo ozna"cimo z $\varepsilon$.
	$$\varepsilon_i = Ax_i^2 + Bx_iy_i + Cy_i^2 + Dx_i + Ey_i + F$$
	Za razliko od premice, je oblika sto"znice odvisna od "sestih parametrov namesto dveh. To so: $A, B, C, D, E$ in $F$. Zato bomo torej spreminjali teh "sest parametrov.

	\paragraph{}
	Podobno kot pri premici najprej definiramo skupno napako kot vsoto kvadratov vseh napak:
	\[\varepsilon = \sum_{i=1}^{N}\varepsilon_i\]
	\[\varepsilon = \sum_{i=1}^{N} (Ax_i^2 + Bx_iy_i + Cy_i^2 + Dx_i + Ey_i + F)^2\]

	\paragraph{}
	Enako kot pri premici moramo na"so napako delno odvajati po spremenjivkah od katerih je na"sa napaka odvisna, da bomo znali te spremenljivke spreminjati pravilno. To pomeni da potrebujemo izra"cunati delni odvod napake po $A, B, C, D, E$ in $F$. Delni odvodi za ena"cbo sto"znic so:

	$$\frac{\partial \varepsilon}{\partial A} = \sum_{i=1}^{N}2(Ax_i^2 + Bx_iy_i + Cy_i^2 + Dx_i + Ey_i + F)(x_i^2)$$
	$$\frac{\partial \varepsilon}{\partial B} = \sum_{i=1}^{N}2(Ax_i^2 + Bx_iy_i + Cy_i^2 + Dx_i + Ey_i + F)(x_iy_i)$$
	$$\frac{\partial \varepsilon}{\partial C} = \sum_{i=1}^{N}2(Ax_i^2 + Bx_iy_i + Cy_i^2 + Dx_i + Ey_i + F)(y_i^2)$$
	$$\frac{\partial \varepsilon}{\partial D} = \sum_{i=1}^{N}2(Ax_i^2 + Bx_iy_i + Cy_i^2 + Dx_i + Ey_i + F)(x_i)$$
	$$\frac{\partial \varepsilon}{\partial E} = \sum_{i=1}^{N}2(Ax_i^2 + Bx_iy_i + Cy_i^2 + Dx_i + Ey_i + F)(y_i)$$
	$$\frac{\partial \varepsilon}{\partial F} = \sum_{i=1}^{N}2(Ax_i^2 + Bx_iy_i + Cy_i^2 + Dx_i + Ey_i + F)$$

	\paragraph{}
	Da najdemo najbolj"se parametre, pri katerih bo funkcija imela najmanj"so napako, bomo ponovno uporabili gradientni spust. Za razliko od gradientnega spusti pri eni premici, bomo tokrat spreminjali "sest parametrov. Na"s gradient je torej:

	$$\nabla \varepsilon = \begin{pmatrix}
	\frac{\partial \varepsilon}{\partial A} &
	\frac{\partial \varepsilon}{\partial B} &
	\frac{\partial \varepsilon}{\partial C} &
	\frac{\partial \varepsilon}{\partial D} &
	\frac{\partial \varepsilon}{\partial E} &
	\frac{\partial \varepsilon}{\partial F}
	\end{pmatrix}$$

	To pomeni da so na"se spremembe parametrov:

	$$\Delta A = -(\nabla \varepsilon)_1 \cdot \lambda$$
	$$\Delta B = -(\nabla \varepsilon)_2 \cdot \lambda$$
	$$\Delta C = -(\nabla \varepsilon)_3 \cdot \lambda$$
	$$\Delta D = -(\nabla \varepsilon)_4 \cdot \lambda$$
	$$\Delta E = -(\nabla \varepsilon)_5 \cdot \lambda$$
	$$\Delta F = -(\nabla \varepsilon)_6 \cdot \lambda$$

	Iz "cesar sledi, da so na"si novi parametri podobno kot pri premici:

	$$A = A + \Delta A$$
	$$B = B + \Delta B$$
	$$C = C + \Delta C$$
	$$D = D + \Delta D$$
	$$E = E + \Delta E$$
	$$F = F + \Delta F$$

	\paragraph{}Pravilnost na"sega rezultata je seveda odvisna od tega koliko ponovitev bomo naredili, kolik"sna bo na"sa $\lambda$ in kak"sne za"cetne vrednosti $A, B, C, D, E$ in $F$ smo si izbrali.

	\section*{Logistična regresija}
	\paragraph{}
	Glavna razlika med logistično in linearno regesijo je, da pri linearni regresiji določamo zvezno spremenljivko ($y$ je odvisen od $x$), medtem ko nam pri logistični regresiji model vrne kakšna je verjetnost, da vhodni podatki sodijo v določeno kategorijo.
	Zato se logistična regresija uporablja za klasifikacijo (npr. prepoznavanje števk idr.).


	\section*{Dodatno}
	\subsection*{Ekliptični koordinatni sistem}
	\paragraph{}
	Eden izmed koordinatnih sistemov za določanje lege nebesnih teles. Lokacijo določimo s tremi podatki. Ker so koordinate definirane glede na ravnino zemljine orbite, je $z$ koordinata za Zemljo vedno enaka 0.
	\begin{description}
		\item[$l$] longtituda, ekliptična dolžina, od $0^\circ$ do $360^\circ$.
		\item[$b$] latituda, ekliptična širina od $-90^\circ$ do $90^\circ$.
		\item[$r$] razdalja
	\end{description}

	\paragraph{}
	V kartezične koordinate podatke pretvorimo po formulah:
	$$x = r \cos b \cos l$$
	$$y = r \cos b \sin l$$
	$$z = r \sin b$$

	\paragraph{}
	Ker tiri vseh planetov ležijo v (skoraj) isti ravnini, bomo $z$ koordianto zanemarili.


\end{document}
